{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style_transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deb-kit2/Neural-Style-Transfer/blob/master/style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MGNEwlyu3Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFZhI-Y6SwD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "work_dir = \"/content/\"\n",
        "os.chdir(\"/content/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezzsN7rgZiM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import vgg16\n",
        "vgg16.maybe_download()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kktPAqGbI_hN",
        "colab_type": "text"
      },
      "source": [
        "Subsequently, the images will be converted to a matrix of entries with type float."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z_v5C5QkYRP",
        "colab_type": "text"
      },
      "source": [
        "The funtion to print the image on-screen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntaHWAgf0oz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def put_on_screen(image):\n",
        "  image = np.clip(image, 0.0, 255.0)             \n",
        "  image = image.astype(np.uint8)\n",
        "  image = PIL.Image.fromarray(image)\n",
        "  display (image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7UdhXi5XsWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def content_image_loss(session, model, content_image, layer_ids):\n",
        "  \n",
        "  feed_dict = model.create_feed_dict(image = content_image)\n",
        "  layers = model.get_layer_tensors(layer_ids = layer_ids)\n",
        "  \n",
        "  value_in_layers = session.run(layers, feed_dict = feed_dict)\n",
        "  \n",
        "  with model.graph.as_default():\n",
        "    \n",
        "    iterator = zip(value_in_layers, layers)                \n",
        "  \n",
        "    content_loss = []\n",
        "  \n",
        "    for value, layer in iterator:\n",
        "      loss = tf.reduce_mean(tf.square(value - layer))        #mean squared error\n",
        "      content_loss.append(loss)\n",
        "    \n",
        "    loss = tf.reduce_mean(content_loss)                      #total loss is the average of all layer losses\n",
        "  return(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8sU_QDfodFg",
        "colab_type": "text"
      },
      "source": [
        "According to the explanation by Andrew Ng, the gram matrix is what the difference is measured against.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UODzUgLksf0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Consider the layer has 5 channels\n",
        "#num_channels = 5\n",
        "\n",
        "def gram_matrix(feature):\n",
        "  shape = feature.get_shape()\n",
        "  num_channels = int(shape[3])\n",
        "  \n",
        "  matrix = tf.reshape(feature, shape = [-1,num_channels])\n",
        "  gram = tf.matmul(tf.transpose(matrix), matrix)\n",
        "  \n",
        "  return(gram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK7mh2xent8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def style_image_loss(session, model, style_image, layer_ids):\n",
        "  \n",
        "  feed_dict = model.create_feed_dict(image = style_image)\n",
        "  layers = model.get_layer_tensors(layer_ids = layer_ids)\n",
        "  \n",
        "  with model.graph.as_default():\n",
        "    gram_for_layer = []\n",
        "    for layer in layers:\n",
        "      gram_for_layer.append(gram_matrix(layer))       \n",
        "      \n",
        "    value_in_layers = session.run(gram_for_layer, feed_dict = feed_dict)\n",
        "    \n",
        "    iterator = zip(value_in_layers, gram_for_layer)\n",
        "    \n",
        "    style_loss = []\n",
        "    \n",
        "    for value, layer in iterator:\n",
        "      loss = tf.reduce_mean(tf.square(value - layer))       \n",
        "      style_loss.append(loss)\n",
        "      \n",
        "    loss = tf.reduce_mean(style_loss)\n",
        "  return(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4drJvrgsnTh",
        "colab_type": "text"
      },
      "source": [
        "Now, constructing the *style_transfer* function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUYSpui8kTLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def style_transfer(style_image, content_image, \n",
        "                   style_id, content_id,\n",
        "                   style_loss_wt = 10, content_loss_wt = 1.5,  \n",
        "                   n_iterations = 100, step = 10 ):\n",
        "  \n",
        "  model = vgg16.VGG16()\n",
        "  session = tf.InteractiveSession(graph = model.graph)\n",
        "  \n",
        "  c_loss = content_image_loss(session = session, model = model, \n",
        "                              content_image = content_image, layer_ids = content_id)\n",
        "  s_loss = style_image_loss(session = session, model = model, \n",
        "                            style_image = style_image, layer_ids = style_id)\n",
        "  \n",
        "  c_loss_update = tf.Variable(1e-10, name = \"c_loss_update\")\n",
        "  s_loss_update = tf.Variable(1e-10, name = \"s_loss_update\")\n",
        "  \n",
        "  session.run([c_loss_update.initializer, s_loss_update.initializer])\n",
        "  \n",
        "  update_c_loss = c_loss_update.assign( 1.0 / (c_loss + 1e-10))\n",
        "  update_s_loss = s_loss_update.assign( 1.0 / (s_loss + 1e-10))\n",
        "  \n",
        "  total_loss = style_loss_wt* s_loss * update_s_loss + \\\n",
        "               content_loss_wt * c_loss * update_c_loss\n",
        "  \n",
        "  gradient = tf.gradients(total_loss, model.input)            \n",
        "  \n",
        "  run_list = [gradient, update_c_loss, update_s_loss]\n",
        "  \n",
        "  result = np.random.rand(*content_image.shape) + 128         #midway\n",
        "  \n",
        "  for i in range(0, n_iterations):\n",
        "    feed_dict = model.create_feed_dict(image = result)\n",
        "    grad, c_loss_a, s_loss_a = session.run(run_list, feed_dict = feed_dict)\n",
        "    \n",
        "    grad = np.squeeze(grad)\n",
        "    result -= grad * step * (1/(np.std(grad) + 1e-10))        #can also use np.mean, this is meant just for normaliztion\n",
        "                                                              #and the 1e-10 is to avoid division by zero, in case\n",
        "    \n",
        "    result = np.clip(result, 0.0, 225.0)                      #this is done to ensure image_values are between 0 and 255\n",
        "    \n",
        "    if (i % 100 == 0) or (i == n_iterations - 1):\n",
        "      print(\"Iteration cycle \", i)\n",
        "    \n",
        "  put_on_screen(result)\n",
        "  session.close()\n",
        "  \n",
        "  return (result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh0ypzBe3H_y",
        "colab_type": "text"
      },
      "source": [
        "trying this out..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g97YGtVxvsZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_image= PIL.Image.open('queen.jpeg')\n",
        "#style_image = Image.open('your_link_here')\n",
        "\n",
        "content_image = PIL.Image.open('test.jpg')\n",
        "#style_image = Image.open('your_link_here')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHpJ57cNv0PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_image = np.float32(style_image) \n",
        "content_image = np.float32(content_image)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_XepSxntSSU",
        "colab_type": "text"
      },
      "source": [
        "VGG16 has 13 convolutional layers, all 13 or some of them can be chosen..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVNJ0da63HFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_ids = [4, 5]\n",
        "style_ids = list(range(0, 13))\n",
        "#style_ids = [5, 6, 7, 8, 9, 10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Qa9rlHAWrr",
        "colab_type": "text"
      },
      "source": [
        "If you choose to do it with a GPU, set a high number of iterations > 1500..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1fOndW83x30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = style_transfer(style_image = style_image, \n",
        "                     content_image = content_image, \n",
        "                     style_id = style_ids, \n",
        "                     content_id = content_ids,\n",
        "                     style_loss_wt = 10, \n",
        "                     content_loss_wt = 2,  \n",
        "                     n_iterations = 2000, \n",
        "                     step = 10 )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}