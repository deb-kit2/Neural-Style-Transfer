{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style_transfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuZ0iwhFylzG",
        "colab_type": "text"
      },
      "source": [
        "Made under Python 3 environment, Google Colab.\n",
        "\n",
        "Hi!\n",
        "\n",
        "So we begin with importing some things we need.\n",
        "\n",
        "I'm importing the file vgg16.py, a well documented file as to import and use the vgg16.tfmodel\n",
        "\n",
        "See the vgg16.py file for documentaion for used functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MGNEwlyu3Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFZhI-Y6SwD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "work_dir = \"/content/\"\n",
        "os.chdir(\"/content/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezzsN7rgZiM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import vgg16\n",
        "vgg16.maybe_download()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6Au-VZCzJIc",
        "colab_type": "text"
      },
      "source": [
        "I did define my functions first.\n",
        "\n",
        "As I made this in Google Colab, I did upload *my* **style_image** and **content_image** into it. If you want to use any other image, just provide the links to them, or you might even use Google Drive.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kktPAqGbI_hN",
        "colab_type": "text"
      },
      "source": [
        "Subsequently, the images will be converted to a matrix of entries with type float."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z_v5C5QkYRP",
        "colab_type": "text"
      },
      "source": [
        "The funtion to print the image on-screen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntaHWAgf0oz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def put_on_screen(image):\n",
        "  image = np.clip(image, 0.0, 255.0)             #to ensure that no values are about 255 or below 0\n",
        "  image = image.astype(np.uint8)\n",
        "  image = PIL.Image.fromarray(image)\n",
        "  display (image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR7eo8Rnftk7",
        "colab_type": "text"
      },
      "source": [
        "I won't go exactly with the paper. I'd make two loss functions for now, I do not understand the thing with denoise, and related losses.\n",
        "\n",
        "*content_loss*, and *style_loss*..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uh_T1kHpugO",
        "colab_type": "text"
      },
      "source": [
        "A front-side, but now too front-sided, layer would be efficient for the *content_losses*, as this layer would bring in the more general features of the image like edges and light differences...\n",
        "\n",
        "The layers at the back involve much higher features like faces, and eyes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7UdhXi5XsWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def content_image_loss(session, model, content_image, layer_ids):\n",
        "  \n",
        "  feed_dict = model.create_feed_dict(image = content_image)\n",
        "  layers = model.get_layer_tensors(layer_ids = layer_ids)\n",
        "  \n",
        "  value_in_layers = session.run(layers, feed_dict = feed_dict)\n",
        "  \n",
        "  with model.graph.as_default():\n",
        "    #I did not know that model.graph needed to be explicitly set as_default.\n",
        "    #I don't know why.\n",
        "    iterator = zip(value_in_layers, layers)                #zip makes a set of the corresponding elements in the two lists\n",
        "  \n",
        "    content_loss = []\n",
        "  \n",
        "    for value, layer in iterator:\n",
        "      loss = tf.reduce_mean(tf.square(value - layer))        #mean squared error\n",
        "      content_loss.append(loss)\n",
        "    \n",
        "    loss = tf.reduce_mean(content_loss)                      #total loss is the average of all layer losses\n",
        "  return(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8sU_QDfodFg",
        "colab_type": "text"
      },
      "source": [
        "According to the explanation by Andrew Ng, the gram matrix is what the difference is measured against.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UODzUgLksf0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Consider the layer has 5 channels\n",
        "#num_channels = 5\n",
        "#we need the product of the activation_values of all points through all these channels. \n",
        "#thus, it is reshaped to a [(suitable_size)xnum_channels] matrix \n",
        "\n",
        "def gram_matrix(feature):\n",
        "  shape = feature.get_shape()\n",
        "  num_channels = int(shape[3])\n",
        "  \n",
        "  matrix = tf.reshape(feature, shape = [-1,num_channels])\n",
        "  gram = tf.matmul(tf.transpose(matrix), matrix)\n",
        "  \n",
        "  return(gram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBHkpe5OrC5w",
        "colab_type": "text"
      },
      "source": [
        "There is no such thing like feature level for *style_image*, all the layers can therefore be included for good results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK7mh2xent8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def style_image_loss(session, model, style_image, layer_ids):\n",
        "  \n",
        "  feed_dict = model.create_feed_dict(image = style_image)\n",
        "  layers = model.get_layer_tensors(layer_ids = layer_ids)\n",
        "  \n",
        "  with model.graph.as_default():\n",
        "    gram_for_layer = []\n",
        "    for layer in layers:\n",
        "      gram_for_layer.append(gram_matrix(layer))            ###################\n",
        "      \n",
        "    value_in_layers = session.run(gram_for_layer, feed_dict = feed_dict)\n",
        "    \n",
        "    iterator = zip(value_in_layers, gram_for_layer)\n",
        "    \n",
        "    style_loss = []\n",
        "    \n",
        "    for value, layer in iterator:\n",
        "      loss = tf.reduce_mean(tf.square(value - layer))        #mean squared error\n",
        "      style_loss.append(loss)\n",
        "      \n",
        "    loss = tf.reduce_mean(style_loss)\n",
        "  return(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4drJvrgsnTh",
        "colab_type": "text"
      },
      "source": [
        "Now, constructing the *style_transfer* function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUYSpui8kTLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def style_transfer(style_image, content_image, \n",
        "                   style_id, content_id,\n",
        "                   style_loss_wt = 10, content_loss_wt = 1.5,  \n",
        "                   n_iterations = 100, step = 10 ):\n",
        "  \n",
        "  model = vgg16.VGG16()\n",
        "  session = tf.InteractiveSession(graph = model.graph)\n",
        "  \n",
        "  c_loss = content_image_loss(session = session, model = model, \n",
        "                              content_image = content_image, layer_ids = content_id)\n",
        "  s_loss = style_image_loss(session = session, model = model, \n",
        "                            style_image = style_image, layer_ids = style_id)\n",
        "  \n",
        "  c_loss_update = tf.Variable(1e-10, name = \"c_loss_update\")\n",
        "  s_loss_update = tf.Variable(1e-10, name = \"s_loss_update\")\n",
        "  ##########################################################################\n",
        "  session.run([c_loss_update.initializer, s_loss_update.initializer])\n",
        "  \n",
        "  update_c_loss = c_loss_update.assign( 1.0 / (c_loss + 1e-10))\n",
        "  update_s_loss = s_loss_update.assign( 1.0 / (s_loss + 1e-10))\n",
        "  \n",
        "  total_loss = style_loss_wt* s_loss * update_s_loss + \\\n",
        "               content_loss_wt * c_loss * update_c_loss\n",
        "  \n",
        "  gradient = tf.gradients(total_loss, model.input)            #returns the derivative of total_loss with respect to\n",
        "                                                              #the model's imput parameters\n",
        "  \n",
        "  run_list = [gradient, update_c_loss, update_s_loss]\n",
        "  \n",
        "  result = np.random.rand(*content_image.shape) + 128         #128 is midway between 0 and 255, min and max values\n",
        "                                                              #thus easier to reach an optimum place\n",
        "  \n",
        "  for i in range(0, n_iterations):\n",
        "    feed_dict = model.create_feed_dict(image = result)\n",
        "    grad, c_loss_a, s_loss_a = session.run(run_list, feed_dict = feed_dict)\n",
        "    \n",
        "    grad = np.squeeze(grad)\n",
        "    result -= grad * step * (1/(np.std(grad) + 1e-10))        #can also use np.mean, this is meant just for normaliztion\n",
        "                                                              #and the 1e-10 is to avoid division by zero, in case\n",
        "    \n",
        "    result = np.clip(result, 0.0, 225.0)                      #this is done to ensure image_values are between 0 and 255\n",
        "    \n",
        "    if (i % 100 == 0) or (i == n_iterations - 1):\n",
        "      print(\"Iteration cycle \", i)\n",
        "    \n",
        "  put_on_screen(result)\n",
        "  session.close()\n",
        "  \n",
        "  return (result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh0ypzBe3H_y",
        "colab_type": "text"
      },
      "source": [
        "trying this out..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g97YGtVxvsZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_image= PIL.Image.open('queen.jpeg')\n",
        "#style_image = Image.open('your_link_here')\n",
        "\n",
        "content_image = PIL.Image.open('test.jpg')\n",
        "#style_image = Image.open('your_link_here')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHpJ57cNv0PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_image = np.float32(style_image) \n",
        "content_image = np.float32(content_image)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_XepSxntSSU",
        "colab_type": "text"
      },
      "source": [
        "VGG16 has 13 convolutional layers, all 13 or some of them can be chosen..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVNJ0da63HFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_ids = [4, 5]\n",
        "style_ids = list(range(0, 13))\n",
        "#style_ids = [5, 6, 7, 8, 9, 10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Qa9rlHAWrr",
        "colab_type": "text"
      },
      "source": [
        "If you choose to do it with a GPU, set a high number of iterations > 1500..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1fOndW83x30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = style_transfer(style_image = style_image, \n",
        "                     content_image = content_image, \n",
        "                     style_id = style_ids, \n",
        "                     content_id = content_ids,\n",
        "                     style_loss_wt = 10, \n",
        "                     content_loss_wt = 2,  \n",
        "                     n_iterations = 2000, \n",
        "                     step = 10 )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}