{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style_transfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuZ0iwhFylzG",
        "colab_type": "text"
      },
      "source": [
        "Made under Python 3 environment, Google Colab.\n",
        "\n",
        "Hi!\n",
        "\n",
        "So we begin with importing some things we need.\n",
        "\n",
        "I'm importing the file vgg16.py, a well documented file as to import and use the vgg16.tfmodel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pui_zDXhoaZ7",
        "colab_type": "text"
      },
      "source": [
        "Resources used :\n",
        "\n",
        "Youtube video by Hvass Technologies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MGNEwlyu3Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFZhI-Y6SwD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "work_dir = \"/content/\"\n",
        "os.chdir(work_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezzsN7rgZiM2",
        "colab_type": "code",
        "outputId": "e5c27f70-39c7-4330-9d5d-9e24685277b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import vgg16\n",
        "vgg16.maybe_download()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading VGG16 Model ...\n",
            "- Download progress: 100.0%\n",
            "Download finished. Extracting files.\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6Au-VZCzJIc",
        "colab_type": "text"
      },
      "source": [
        "I did define my functions first.\n",
        "\n",
        "As I made this in Google Colab, I did upload *my* **style_image** and **content_image** into it. If you want to use any other image, just provide the links to them, or you might even use Google Drive.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kktPAqGbI_hN",
        "colab_type": "text"
      },
      "source": [
        "I used 512x512 images. Resize if you want to.\n",
        "\n",
        "Subsequently, the images will be converted to a matrix of entries with type float."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIuBJMnHg5Ch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad4ec73d-344d-4c78-cb88-2590890b663f"
      },
      "source": [
        "\"\"\"\n",
        "  def resize(image, size):\n",
        "  \n",
        "\"\"\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  def resize(image, size):\\n  \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntaHWAgf0oz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def put_on_screen(image):\n",
        "  image = np.clip(image, 0.0, 255.0)\n",
        "  image = image.astype(np.uint8)\n",
        "  image = PIL.Image.fromarray(image)\n",
        "  display (image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR7eo8Rnftk7",
        "colab_type": "text"
      },
      "source": [
        "I won't go exactly with the paper. I'd make two loss functions for now, \n",
        "\n",
        "*content_loss*, and *style_loss*..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7UdhXi5XsWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def content_image_loss(session, model, content_image, layer_ids):\n",
        "  \n",
        "  feed_dict = model.create_feed_dict(image = content_image)\n",
        "  layers = model.get_layer_tensors(layer_ids = layer_ids)\n",
        "  \n",
        "  value_in_layers = session.run(layers, feed_dict = feed_dict)\n",
        "  \n",
        "  with model.graph.as_default():\n",
        "    iterator = zip(value_in_layers, layers)                ###############################\n",
        "  \n",
        "    content_loss = []\n",
        "  \n",
        "    for value, layer in iterator:\n",
        "      loss = tf.reduce_mean(tf.square(value - layer))        #mean squared error\n",
        "      content_loss.append(loss)\n",
        "    \n",
        "    loss = tf.reduce_mean(content_loss)                      #total loss is the average of all layer losses\n",
        "  return(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UODzUgLksf0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Consider the layer has 5 channels\n",
        "#num_channels = 5\n",
        "#we need the product of the activation_values of all points through all these channels. \n",
        "#thus, it is reshaped to a [(suitable_size)xnum_channels] matrix \n",
        "\n",
        "def gram_matrix(feature):\n",
        "  shape = feature.get_shape()\n",
        "  num_channels = int(shape[3])\n",
        "  \n",
        "  matrix = tf.reshape(feature, shape = [-1,num_channels])\n",
        "  gram = tf.matmul(tf.transpose(matrix), matrix)\n",
        "  \n",
        "  return(gram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK7mh2xent8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def style_image_loss(session, model, style_image, layer_ids):\n",
        "  \n",
        "  feed_dict = model.create_feed_dict(image = style_image)\n",
        "  layers = model.get_layer_tensors(layer_ids = layer_ids)\n",
        "  \n",
        "  with model.graph.as_default():\n",
        "    gram_for_layer = []\n",
        "    for layer in layers:\n",
        "      gram_for_layer.append(gram_matrix(layer))            ###################\n",
        "      \n",
        "    value_in_layers = session.run(gram_for_layer, feed_dict = feed_dict)\n",
        "    \n",
        "    iterator = zip(value_in_layers, gram_for_layer)\n",
        "    \n",
        "    style_loss = []\n",
        "    \n",
        "    for value, layer in iterator:\n",
        "      loss = tf.reduce_mean(tf.square(value - layer))        #mean squared error\n",
        "      style_loss.append(loss)\n",
        "      \n",
        "    loss = tf.reduce_mean(style_loss)\n",
        "  return(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUYSpui8kTLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def style_transfer(style_image, content_image, \n",
        "                   style_id, content_id,\n",
        "                   style_loss_wt = 10, content_loss_wt = 1.5,  \n",
        "                   n_iterations = 100, step = 10 ):\n",
        "  \n",
        "  model = vgg16.VGG16()\n",
        "  session = tf.InteractiveSession(graph = model.graph)\n",
        "  \n",
        "  c_loss = content_image_loss(session = session, model = model, \n",
        "                              content_image = content_image, layer_ids = content_id)\n",
        "  s_loss = style_image_loss(session = session, model = model, \n",
        "                            style_image = style_image, layer_ids = style_id)\n",
        "  \n",
        "  c_loss_update = tf.Variable(1e-10, name = \"c_loss_update\")\n",
        "  s_loss_update = tf.Variable(1e-10, name = \"s_loss_update\")\n",
        "  ##########################################################################\n",
        "  session.run([c_loss_update.initializer, s_loss_update.initializer])\n",
        "  \n",
        "  update_c_loss = c_loss_update.assign( 1.0 / (c_loss + 1e-10))\n",
        "  update_s_loss = s_loss_update.assign( 1.0 / (s_loss + 1e-10))\n",
        "  \n",
        "  total_loss = style_loss_wt* s_loss * update_s_loss + \\\n",
        "               content_loss_wt * c_loss * update_c_loss\n",
        "  \n",
        "  gradient = tf.gradients(total_loss, model.input)\n",
        "  \n",
        "  run_list = [gradient, update_c_loss, update_s_loss]\n",
        "  \n",
        "  result = np.random.rand(*content_image.shape) + 128         #128 is midway between 0 and 255, min and max values\n",
        "  \n",
        "  for i in range(0, n_iterations):\n",
        "    feed_dict = model.create_feed_dict(image = result)\n",
        "    grad, c_loss_a, s_loss_a = session.run(run_list, feed_dict = feed_dict)\n",
        "    \n",
        "    grad = np.squeeze(grad)\n",
        "    result -= grad * step * (1/(np.std(grad) + 1e-8)) ################################\n",
        "    \n",
        "    result = np.clip(result, 0.0, 225.0)\n",
        "    \n",
        "    if (i % 10 == 0) or (i == n_iterations - 1):\n",
        "      print(\"Iteration:\", i)\n",
        "    \n",
        "  put_on_screen(result)\n",
        "  session.close()\n",
        "  \n",
        "  return (result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh0ypzBe3H_y",
        "colab_type": "text"
      },
      "source": [
        "trying this out..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g97YGtVxvsZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_image= PIL.Image.open('style_image.jpg')\n",
        "#style_image = Image.open('your_link_here')\n",
        "\n",
        "content_image = PIL.Image.open('content_image.jpg')\n",
        "#style_image = Image.open('your_link_here')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHpJ57cNv0PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_image = np.float32(style_image) \n",
        "content_image = np.float32(content_image)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVNJ0da63HFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_ids = [4]\n",
        "style_ids = list(range(13))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1fOndW83x30",
        "colab_type": "code",
        "outputId": "79d37f38-c63e-44c0-c016-f87815003612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "img = style_transfer(style_image = style_image, \n",
        "                     content_image = content_image, \n",
        "                     style_id = style_ids, \n",
        "                     content_id = content_ids,\n",
        "                     style_loss_wt = 10, \n",
        "                     content_loss_wt = 1.5,  \n",
        "                     n_iterations = 100, \n",
        "                     step = 10 )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0719 16:01:16.187609 140191825016704 deprecation.py:323] From /content/vgg16.py:107: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "W0719 16:01:16.189714 140191825016704 deprecation_wrapper.py:119] From /content/vgg16.py:110: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0\n",
            "Iteration: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a6cf3454f078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                      \u001b[0mcontent_loss_wt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                      \u001b[0mn_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                      step = 10 )\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-3d40ad36f119>\u001b[0m in \u001b[0;36mstyle_transfer\u001b[0;34m(style_image, content_image, style_id, content_id, style_loss_wt, content_loss_wt, n_iterations, step)\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_loss_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_loss_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}